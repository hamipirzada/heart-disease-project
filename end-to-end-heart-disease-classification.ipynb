{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "convinced-oriental",
   "metadata": {},
   "source": [
    "# Predicting heart disease using machiine learning\n",
    "\n",
    "This notebook looks into using various Python-based machine learning and data science libraries in an attempt to build a \n",
    "machine learning model capable of predicting whether or not someone has heart disease based on their medical attributes.\n",
    "\n",
    "We're going to take the following approach:\n",
    "    1. `Problem definition`\n",
    "    2. `Data`\n",
    "    3. `Evaluation`\n",
    "    4. `Features`\n",
    "    5. `Modelling`\n",
    "    6. `Experimentation`\n",
    "    \n",
    "## 1. Problem Definition\n",
    "\n",
    "In a statement,\n",
    "> Given clinical parameters about a patient whether or not they have heart disease?\n",
    "\n",
    "## 2. Data\n",
    "\n",
    "The original data came from the Cleavlandd data from the UCI Machine Learning Repository. https://archive.ics.uci.edu/ml/datasets/heart+disease\n",
    "There is also a version of it available on Kaggle. https://www.kaggle.com/ronitf/heart-disease-uci\n",
    "\n",
    "## 3. Evaluation \n",
    "\n",
    "> If we can reach 95% accuracy at predicting whether or not a patient has heart disease during the proof of concept, we'll pursue the project.\n",
    "\n",
    "## 4. Features\n",
    "\n",
    "This is where you'll get different information about each of the features in your data.\n",
    "\n",
    "**Create data dictionary**\n",
    "\n",
    "* age in years\n",
    "* sex(1 = male; 0 = female)\n",
    "* cp chest pain type\n",
    "* trestbps resting blood pressure (in mm Hg on admission to the hospital)\n",
    "* cholserum cholestoral in mg/dl\n",
    "* fbs(fasting blood sugar &gt; 120 mg/dl) (1 = true; 0 = false)\n",
    "* restecgresting electrocardiographic results\n",
    "* thalach maximum heart rate achieved\n",
    "* exang exercise induced angina (1 = yes; 0 = no)\n",
    "* oldpeak ST depression induced by exercise relative to rest\n",
    "* slope the slope of the peak exercise ST segment\n",
    "* ca number of major vessels (0-3) colored by flourosopy\n",
    "* thal3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "* target - have heart disease or not (1=yes, 0=no)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-characterization",
   "metadata": {},
   "source": [
    "## Preparing the tools \n",
    "\n",
    "We're going to use Pandas, Matplotlib and Numpy for data analysis and manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the tols we need\n",
    "\n",
    "# Regular EDA(exploratory data analysis) and plotting libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# we want our plots to appear inside the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Models from Scikit-Learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Model evaluations\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-champagne",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"heart-disease.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-enlargement",
   "metadata": {},
   "source": [
    "## Data Exploratory (exploratory data analysis or EDA)\n",
    "\n",
    "The goal is to find out more about the data and become a subject matter expert on the dataset you're working with\n",
    "\n",
    "1. What question(s) are you trying to solve?\n",
    "2. What kind of data do we have and how do we treat different types?\n",
    "3. What's missing from the data and how do you deal with it?\n",
    "4. Where are the outliers and why should youcare about them?\n",
    "5. How can you add, change or remove features to get more out of your data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-landing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find out how many of each class there\n",
    "df[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target\"].value_counts().plot(kind=\"bar\", color=[\"salmon\", \"lightblue\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-examination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any missing data?\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-archive",
   "metadata": {},
   "source": [
    "### Heart Disease Frequency according to Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare target column with sex column\n",
    "pd.crosstab(df.target, df.sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.target, df.sex).plot(kind = \"bar\",\n",
    "                                    figsize = (10, 6),\n",
    "                                    color = [\"salmon\", \"lightblue\"]);\n",
    "plt.title(\"Heart Disease Frequency for Sex\")\n",
    "plt.xlabel(\"0 = No Disease, 1 = Disease\")\n",
    "plt.ylabel(\"Amount\")\n",
    "plt.legend([\"Female\", \"Male\"])\n",
    "plt.xticks(rotation=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-seller",
   "metadata": {},
   "source": [
    "### Age vs Max Heart Rate for Hear Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another figure\n",
    "plt.figure(figsize=(10, 6));\n",
    "\n",
    "# Scatter with positive Examples\n",
    "plt.scatter(df.age[df.target==1],\n",
    "            df.thalach[df.target==1],\n",
    "            c=\"salmon\");\n",
    "# Scatter with negative Examples\n",
    "plt.scatter(df.age[df.target==0],\n",
    "            df.thalach[df.target==0],\n",
    "            c=\"lightblue\");\n",
    "# Add some helpful info\n",
    "plt.title(\"Heart Disease in function of Age and Max Heart Rate\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"max Heart Rate\")\n",
    "plt.legend([\"Disease\", \"No Disease\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of the age column with a histogram\n",
    "df.age.plot.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-communications",
   "metadata": {},
   "source": [
    "### Heart Disease Frequency per Chest Pain Type\n",
    "\n",
    "cp-chest pain type\n",
    "    * **0: Typical angina**: chest pain related decrease blood sugar supply to the heart\n",
    "    * **1: Atypical angina**: chest pain not related to heart\n",
    "    * **2: Non-anginal pain**: typically esophageal spasms (non heart related)\n",
    "    * **3: Asymptomatic**: chest pain not showing signs of disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-shadow",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.cp, df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the crosstab more visual\n",
    "pd.crosstab(df.cp, df.target).plot(kind=\"bar\",\n",
    "                                   figsize=(10, 6),\n",
    "                                   color=[\"salmon\", \"lightblue\"])\n",
    "# Add some communication\n",
    "plt.title(\"Heart Disease Frequency per Chest Pain Type\")\n",
    "plt.xlabel(\"Chest Pain Type\")\n",
    "plt.ylabel(\"Amount\")\n",
    "plt.legend([\"No Disease\", \"Disease\"])\n",
    "plt.xticks(rotation=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make correlation matrix\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets make our correlation matrix a little prettier\n",
    "corr_matrix = df.corr()\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "ax = sns.heatmap(corr_matrix,\n",
    "                 annot=True,\n",
    "                 linewidths=1,\n",
    "                 fmt=\".2f\",\n",
    "                 cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-bandwidth",
   "metadata": {},
   "source": [
    "### 5. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into X and y\n",
    "X = df.drop(\"target\", axis=1)\n",
    "\n",
    "y = df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-martial",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "included-baseline",
   "metadata": {},
   "source": [
    "Now we have got our data split into training and test sets, it's time to build a machine learning model.\n",
    "We will train(find patterns) on the training set.\n",
    "And we will test it (use patterns) on the test sets.\n",
    "\n",
    "We are going to try 3 different machine learning models:\n",
    "1. Logistic Regression\n",
    "2. K-Nearest Neighbors Classifier\n",
    "3. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put models in a dictionary\n",
    "models = {\"Logistic Regression\": LogisticRegression(),\n",
    "          \"KNN\": KNeighborsClassifier(),\n",
    "          \"Random Forest\": RandomForestClassifier()}\n",
    "# Create a function to fit and score models.\n",
    "def fit_and_score(models, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "        Fits and evaluates given machine learning models.\n",
    "        models: a dict of different Scikit-learn machine learning models\n",
    "        X_train: training data (no labels)\n",
    "        X_test: testing data (no labels)\n",
    "        y_train: training labels\n",
    "        y_test: testing  labels\n",
    "    \"\"\"\n",
    "    #Setup a random seed\n",
    "    np.random.seed(42)\n",
    "    # Make a dictionary to keep model scores\n",
    "    model_scores = {}\n",
    "    # Loop through models \n",
    "    for name, model in models.items():\n",
    "        # Fit the model to the data\n",
    "        model.fit(X_train, y_train)\n",
    "        # Evaluate the model and append its score to model_scores\n",
    "        model_scores[name] = model.score(X_test, y_test)\n",
    "    return model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = fit_and_score(models=models,\n",
    "                             X_train=X_train,\n",
    "                             X_test=X_test,\n",
    "                             y_train=y_train,\n",
    "                             y_test=y_test)\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-perry",
   "metadata": {},
   "source": [
    "### Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-profit",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_compare = pd.DataFrame(model_scores, index=[\"accuracy\"])\n",
    "model_compare.T.plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-juice",
   "metadata": {},
   "source": [
    "Now we have got a baseline model... and we know a model's first predictions aren't what we should based our next steps off.\n",
    "What should we do?\n",
    "\n",
    "Let's look at the following:\n",
    "* Hyperparameter Tuning\n",
    "* Feature importance \n",
    "* Confusion matrix\n",
    "* Cross-validation\n",
    "* Precision\n",
    "* Recall\n",
    "* F1 score\n",
    "* Classification report\n",
    "* ROC curve\n",
    "* Area under the curve (AUC)\n",
    "\n",
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's tune KNN\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "# Create a list of different values for n_neighbors\n",
    "neighbors = range(1, 21)\n",
    "\n",
    "# Setup KNN instance \n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Loop through different n_neighbors\n",
    "for i in neighbors:\n",
    "    knn.set_params(n_neighbors=i)\n",
    "    \n",
    "    # Fit the algorithm\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Update the training scores list\n",
    "    train_scores.append(knn.score(X_train, y_train))\n",
    "    \n",
    "    # Update the test scores list\n",
    "    test_scores.append(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-graduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(neighbors, train_scores, label=\"Train score\")\n",
    "plt.plot(neighbors, test_scores, label=\"Test score\")\n",
    "plt.xticks(np.arange(1,21,1))\n",
    "plt.xlabel(\"Number of neighbors\")\n",
    "plt.ylabel(\"Model score\")\n",
    "plt.legend()\n",
    "\n",
    "print(f\"Maximum KNN score on the test data:{max(test_scores)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-worth",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning with RandomizedSearchCV\n",
    "We're going to use:\n",
    "\n",
    "* LogisticRegression()\n",
    "* RandomForestSearch()\n",
    "\n",
    "...using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-college",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hyperparameter grid for LogisticRegression\n",
    "log_reg_grid = {\"C\": np.logspace(-4, 4, 20),\n",
    "                \"solver\": [\"liblinear\"]}\n",
    "\n",
    "# Create a hyperparameter grid for RandomForestClassifier\n",
    "rf_grid = {\"n_estimators\": np.arange(10, 1000, 50),\n",
    "           \"max_depth\": [None, 3, 5, 10],\n",
    "           \"min_samples_split\": np.arange(2, 20, 2),\n",
    "           \"min_samples_leaf\": np.arange(1, 20, 2)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-salad",
   "metadata": {},
   "source": [
    "Now we have got hyperparameter grids setup for each of our models, let's tune them using RandomizedSearchCV..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune LogisticRegression\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Setup random hyperparameter search for LogisticRegression\n",
    "rs_log_reg = RandomizedSearchCV(LogisticRegression(),\n",
    "                                param_distributions = log_reg_grid,\n",
    "                                cv = 5,\n",
    "                                n_iter = 20,\n",
    "                                verbose = True)\n",
    "\n",
    "# Fit random hyperparameter search model for LogisticRegression\n",
    "rs_log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_log_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-reproduction",
   "metadata": {},
   "source": [
    "Now we've tuned LogisticRegression(), let's do the same for RandomForestClassifier()..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-visit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Setup random hyperparameter search for RandomForestClassifier\n",
    "rs_rf = RandomizedSearchCV(RandomForestClassifier(),\n",
    "                           param_distributions = rf_grid,\n",
    "                           cv = 5,\n",
    "                           n_iter = 20,\n",
    "                           verbose = True)\n",
    "# Fit random hyperparameter search model for RandomForestClassifier\n",
    "rs_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-trauma",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-flour",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
